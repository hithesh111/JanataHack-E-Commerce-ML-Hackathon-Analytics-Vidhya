{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>JanataHack E-Commerce Analytics ML Hackathon</h1>\n",
    "<p>Predicting gender of a user from e-commerce data</p>\n",
    "\n",
    "<h2>Initial Approach and Progress</h2>\n",
    "<p>First submission was a Gradient Boost model using only one or two time variables and 'A' and 'B' sparse columns (No of views in category A1,...,A11 and subcategory B01,...,B91).It got a score of 0.851.<br><br>\n",
    "Then I added sub-subcategory sparse columns(C001,...,C436) and features like Interval, WeekDay and No_of_Views and the score went upto 0.864.<br><br>\n",
    "Guessed that the first two digits after D in the product code might help and tried adding a few highly correlated ones. Adding all of such features D00,...,D99 took the score to 0.875<br><br>\n",
    "Tried all digit wise features instead of the above sparse columns 'A','B' and 'C' but didn't help.<br><br>\n",
    "Adding 4th and 5th digits also improved score a little. Now, changing the model to XGBoost gave a surprisingly good increase in score(0.897).<br><br>\n",
    "Adding N_Categories variables(and related) and Christmas variable helped (0.904) but NewYear didn't. Removed a few other useless or redundant features too.<br><br>\n",
    "Increased n_estimators parameter of XGBoost from 100(default) to 1000, 3000 and then 10000 and noticed improvement in the score(0.908,0.922,0.926 respectively).\n",
    "</p>\n",
    "\n",
    "<h2>Final Model</h2>\n",
    "<h4>Won 10th place (92.6% score on Public data, 92.1% score on Private data)</h4>\n",
    "<p>Given below is the code for the final submission.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing important libraries, models and tools</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hithesh/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/hithesh/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading train data and encoding gender column </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  session_id       startTime         endTime  \\\n",
      "0     u16159  15/12/14 18:11  15/12/14 18:12   \n",
      "1     u10253  16/12/14 14:35  16/12/14 14:41   \n",
      "2     u19037  01/12/14 15:58  01/12/14 15:58   \n",
      "3     u14556   23/11/14 2:57   23/11/14 3:00   \n",
      "4     u24295  17/12/14 16:44  17/12/14 16:46   \n",
      "\n",
      "                                         ProductList  gender  \n",
      "0  A00002/B00003/C00006/D28435/;A00002/B00003/C00...  female  \n",
      "1  A00001/B00009/C00031/D29404/;A00001/B00009/C00...    male  \n",
      "2                       A00002/B00001/C00020/D16944/  female  \n",
      "3  A00002/B00004/C00018/D10284/;A00002/B00004/C00...  female  \n",
      "4  A00001/B00001/C00012/D30805/;A00001/B00001/C00...    male  \n",
      "  session_id       startTime         endTime  \\\n",
      "0     u16159  15/12/14 18:11  15/12/14 18:12   \n",
      "1     u10253  16/12/14 14:35  16/12/14 14:41   \n",
      "2     u19037  01/12/14 15:58  01/12/14 15:58   \n",
      "3     u14556   23/11/14 2:57   23/11/14 3:00   \n",
      "4     u24295  17/12/14 16:44  17/12/14 16:46   \n",
      "\n",
      "                                         ProductList  gender  \n",
      "0  A00002/B00003/C00006/D28435/;A00002/B00003/C00...       0  \n",
      "1  A00001/B00009/C00031/D29404/;A00001/B00009/C00...       1  \n",
      "2                       A00002/B00001/C00020/D16944/       0  \n",
      "3  A00002/B00004/C00018/D10284/;A00002/B00004/C00...       0  \n",
      "4  A00001/B00001/C00012/D30805/;A00001/B00001/C00...       1  \n"
     ]
    }
   ],
   "source": [
    "path = '/home/hithesh/Desktop/ML Competitions/ECommerce_Analytics_Vidhya/train_8wry4cB.csv'\n",
    "df = pd.read_csv(path)\n",
    "print(df.head())\n",
    "df['gender'] = df['gender'].apply(lambda x: 0 if x=='female' else 1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extracting Day,Month,Hour and Minute from the Date-Time Variables (startTime and endTime)</h3>\n",
    "Year wasn't extracted because all of the data is from the year 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['startTime'] = df['startTime'].apply(lambda x:x.replace('/',' '))\n",
    "df['endTime'] = df['endTime'].apply(lambda x:x.replace('/',' '))\n",
    "\n",
    "df['Date'] = df['startTime'].apply(lambda x: datetime.datetime(2000+int(x.split(' ')[2]),int(x.split(' ')[1]),int(x.split(' ')[0])))\n",
    "\n",
    "df['STime'] = df['startTime'].apply(lambda x: 60*int(x.split(' ')[3].split(':')[0]) + int(x.split(' ')[3].split(':')[1]))\n",
    "df['ETime'] = df['endTime'].apply(lambda x: 60*int(x.split(' ')[3].split(':')[0]) + int(x.split(' ')[3].split(':')[1]))\n",
    "\n",
    "df['SHour'] = df['startTime'].apply(lambda x: int(x.split(' ')[3].split(':')[0]))\n",
    "df['EHour'] = df['endTime'].apply(lambda x: int(x.split(' ')[3].split(':')[0]))\n",
    "\n",
    "df['SMonth'] = df['startTime'].apply(lambda x: int(x.split(' ')[1]))\n",
    "df['EMonth'] = df['endTime'].apply(lambda x: int(x.split(' ')[1]))\n",
    "\n",
    "df['SDay'] = df['startTime'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df['EDay'] = df['endTime'].apply(lambda x: int(x.split(' ')[0]))\n",
    "\n",
    "df['SMinute'] = df['startTime'].apply(lambda x: int(x.split(' ')[3].split(':')[1]))\n",
    "df['EMinute'] = df['endTime'].apply(lambda x: int(x.split(' ')[3].split(':')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating new features from session_id and date and time features (Possibly useful)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hithesh/anaconda3/lib/python3.7/site-packages/pandas/core/computation/expressions.py:183: UserWarning: evaluating in Python space because the '*' operator is not supported by numexpr for the bool dtype, use '&' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "df['SessId'] = df['session_id'].apply(lambda x: int(x.split('u')[1]))\n",
    "\n",
    "df['Interval'] = (df['ETime'] - df['STime'])*(df['ETime']>=df['STime']) + (2400-df['STime']+df['ETime'])*(df['ETime']<df['STime'])\n",
    "\n",
    "df['Inactive'] = (df['SDay']!=df['EDay']) \n",
    "\n",
    "df['WeekDay'] = df['Date'].apply(lambda x: x.weekday())\n",
    "\n",
    "df['Christmas'] = (df['SDay'] >= 23)*(df['SDay']<=25)*(df['SMonth']==12)\n",
    "\n",
    "df['NewYear'] = (df['SDay']>=28)*(df['SDay']<=30)*(df['SMonth']==12)\n",
    "\n",
    "df['Work'] = df['startTime'].apply(lambda x: 1 if int(x.split(' ')[3].split(':')[0])>=9 and int(x.split(' ')[3].split(':')[0])<=17 and datetime.datetime(2000+int(x.split(' ')[2]),int(x.split(' ')[1]),int(x.split(' ')[2])).weekday()<=4 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Total number of products viewed and products viewed per time spent as features</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_list = df['ProductList']\n",
    "\n",
    "df['No_of_Views'] = pd.Series(np.zeros(len(prod_list)))\n",
    "\n",
    "for i in range(len(prod_list)):\n",
    "    string = prod_list[i]\n",
    "    no_prods = int(string.count('/')/4)\n",
    "    prod = string.split(';')\n",
    "    df.loc[i,'No_of_Views']=len(prod)\n",
    "    \n",
    "df['Speed'] = (df['No_of_Views'])/(df['Interval']+0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating Sparse features for categories and subcategories A1,...,A11, B01,...B91, C001,...,C436</h3>\n",
    "Each of these columns indicate the number of products viewed in the respective category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1,437):\n",
    "    if(m):\n",
    "        if(m<10):\n",
    "            df['C00'+str(m)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(m>=10 and m<100):\n",
    "            df['C0'+str(m)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(m>=100):\n",
    "            df['C'+str(m)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(m)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[2][-3:] == '0'+str(m) or prod[j].split('/')[2][-3:] == str(m) or prod[j].split('/')[2][-3:]=='00'+str(m)):\n",
    "                if(m<10):\n",
    "                    df.loc[i,'C00'+str(m)] += 1\n",
    "                if(m>=10 and m<100):\n",
    "                    df.loc[i,'C0'+str(m)] += 1\n",
    "                if(m>=100):\n",
    "                    df.loc[i,'C'+str(m)] += 1\n",
    "\n",
    "for l in range(1,92):\n",
    "    if(l):\n",
    "        if(l>=10):\n",
    "            df['B'+str(l)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(l<10):\n",
    "            df['B0'+str(l)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(l)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[1][-2:] == '0'+str(l) or prod[j].split('/')[1][-2:] == str(l)):\n",
    "                if(l<10):\n",
    "                    df.loc[i,'B0'+str(l)] += 1\n",
    "                if(l>=10):\n",
    "                    df.loc[i,'B'+str(l)] += 1\n",
    "            \n",
    "    \n",
    "for k in range(1,12):\n",
    "    if(k>=10):\n",
    "        df['A'+str(k)] = pd.Series(np.zeros(len(prod_list)))\n",
    "    else:\n",
    "        df['A0'+str(k)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(k)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[0][-2:] == '0'+str(k) or prod[j].split('/')[0][-2:] == str(k)):\n",
    "                if(k<10):\n",
    "                    df.loc[i,'A0'+str(k)] += 1\n",
    "                else:\n",
    "                    df.loc[i,'A'+str(k)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>More Sparse Features using the Product Code</h3>\n",
    " Third digit after 'D',4th and 5th digits after 'D', 1st and 2nd digits after 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(0,10):\n",
    "    df['E'+str(p)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(p)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[3][3] == str(p)):\n",
    "                df.loc[i,'E'+str(p)] += 1\n",
    "                    \n",
    "for o in range(0,100):\n",
    "    if(o>-1):\n",
    "        if(o<10):\n",
    "            df['F0'+str(o)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(o>=10):\n",
    "            df['F'+str(o)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(o)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[3][4:6] == '0' +str(o) or prod[j].split('/')[3][4:6] == str(o)):\n",
    "                if(o<10):\n",
    "                    df.loc[i,'F0'+str(o)] += 1\n",
    "                if(o>=10):\n",
    "                    df.loc[i,'F'+str(o)] += 1    \n",
    "    \n",
    "for n in range(0,100):\n",
    "    if(n>-1):\n",
    "        if(n<10):\n",
    "            df['D0'+str(n)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(n>=10):\n",
    "            df['D'+str(n)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(n)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[3][1:3] == '0'+str(n) or prod[j].split('/')[3][1:3] == str(n)):\n",
    "                if(n<10):\n",
    "                    df.loc[i,'D0'+str(n)] += 1\n",
    "                if(n>=10):\n",
    "                    df.loc[i,'D'+str(n)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Features indicating number of categories and subcategories viewed, per total product views and per time spent</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['N_CategoriesA'] = pd.Series(np.zeros(len(prod_list)))\n",
    "for i in range(1,12):\n",
    "    if(i<10):\n",
    "        df['N_CategoriesA'] += df['A0'+str(i)]>0\n",
    "    else:\n",
    "        df['N_CategoriesA'] += df['A'+str(i)]>0\n",
    "df['Cat_PropA'] = df['N_CategoriesA']/df['No_of_Views']\n",
    "df['Cat_SpeedA'] = df['N_CategoriesA']/(df['Interval']+0.01)\n",
    "\n",
    "df['N_CategoriesB'] = pd.Series(np.zeros(len(prod_list)))\n",
    "for i in range(1,92):\n",
    "    if(i<10):\n",
    "        df['N_CategoriesB'] += df['B0'+str(i)]>0\n",
    "    else:\n",
    "        df['N_CategoriesB'] += df['B'+str(i)]>0       \n",
    "df['Cat_PropB'] = df['N_CategoriesB']/df['No_of_Views']\n",
    "df['Cat_SpeedB'] = df['N_CategoriesB']/(df['Interval']+0.01)\n",
    "\n",
    "df['N_CategoriesC'] = pd.Series(np.zeros(len(prod_list)))\n",
    "for i in range(1,437):\n",
    "    if(i>=100):\n",
    "        df['N_CategoriesC'] += df['C'+str(i)]>0\n",
    "    elif(i>=10):\n",
    "        df['N_CategoriesC'] += df['C0'+str(i)]>0\n",
    "    else:\n",
    "        df['N_CategoriesC'] +=df['C00'+str(i)]>0     \n",
    "df['Cat_PropC'] = df['N_CategoriesC']/df['No_of_Views']\n",
    "df['Cat_SpeedC'] = df['N_CategoriesC']/(df['Interval']+0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saving the dataframe with new features</h3>\n",
    "Note: I used two python files initially (combined them now), one for feature engineering and other to test the model. So this step was only to facilitate that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['ProductList'],axis=1)\n",
    "df.to_csv('/home/hithesh/Desktop/ML Competitions/ECommerce_Analytics_Vidhya/mod_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  session_id       startTime         endTime  \\\n",
      "0     u12112  08/12/14 13:36  08/12/14 13:36   \n",
      "1     u19725  19/12/14 13:52  19/12/14 13:52   \n",
      "2     u11795  01/12/14 10:44  01/12/14 10:44   \n",
      "3     u22639  08/12/14 20:19  08/12/14 20:22   \n",
      "4     u18034  15/12/14 19:33  15/12/14 19:33   \n",
      "\n",
      "                                         ProductList  \n",
      "0                       A00002/B00003/C00006/D19956/  \n",
      "1                       A00002/B00005/C00067/D02026/  \n",
      "2                       A00002/B00002/C00004/D12538/  \n",
      "3  A00002/B00003/C00079/D22781/;A00002/B00003/C00...  \n",
      "4                       A00002/B00001/C00010/D23419/  \n"
     ]
    }
   ],
   "source": [
    "path = '/home/hithesh/Desktop/ML Competitions/ECommerce_Analytics_Vidhya/test_Yix80N0.csv'\n",
    "df = pd.read_csv(path)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extracting Day,Month,Hour and Minute from the Date-Time Variables (startTime and endTime) - For test data</h3>\n",
    "Year wasn't extracted because all of the data is from the year 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['startTime'] = df['startTime'].apply(lambda x:x.replace('/',' '))\n",
    "df['endTime'] = df['endTime'].apply(lambda x:x.replace('/',' '))\n",
    "\n",
    "df['Date'] = df['startTime'].apply(lambda x: datetime.datetime(2000+int(x.split(' ')[2]),int(x.split(' ')[1]),int(x.split(' ')[0])))\n",
    "\n",
    "df['STime'] = df['startTime'].apply(lambda x: 60*int(x.split(' ')[3].split(':')[0]) + int(x.split(' ')[3].split(':')[1]))\n",
    "df['ETime'] = df['endTime'].apply(lambda x: 60*int(x.split(' ')[3].split(':')[0]) + int(x.split(' ')[3].split(':')[1]))\n",
    "\n",
    "df['SHour'] = df['startTime'].apply(lambda x: int(x.split(' ')[3].split(':')[0]))\n",
    "df['EHour'] = df['endTime'].apply(lambda x: int(x.split(' ')[3].split(':')[0]))\n",
    "\n",
    "df['SMonth'] = df['startTime'].apply(lambda x: int(x.split(' ')[1]))\n",
    "df['EMonth'] = df['endTime'].apply(lambda x: int(x.split(' ')[1]))\n",
    "\n",
    "df['SDay'] = df['startTime'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df['EDay'] = df['endTime'].apply(lambda x: int(x.split(' ')[0]))\n",
    "\n",
    "df['SMinute'] = df['startTime'].apply(lambda x: int(x.split(' ')[3].split(':')[1]))\n",
    "df['EMinute'] = df['endTime'].apply(lambda x: int(x.split(' ')[3].split(':')[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating new features from session_id and date and time features (Possibly useful) - For test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SessId'] = df['session_id'].apply(lambda x: int(x.split('u')[1]))\n",
    "\n",
    "df['Interval'] = (df['ETime'] - df['STime'])*(df['ETime']>=df['STime']) + (2400-df['STime']+df['ETime'])*(df['ETime']<df['STime'])\n",
    "\n",
    "df['Inactive'] = (df['SDay']!=df['EDay']) \n",
    "\n",
    "df['WeekDay'] = df['Date'].apply(lambda x: x.weekday())\n",
    "\n",
    "df['Christmas'] = (df['SDay'] >= 23)*(df['SDay']<=25)*(df['SMonth']==12)\n",
    "\n",
    "df['NewYear'] = (df['SDay']>=28)*(df['SDay']<=30)*(df['SMonth']==12)\n",
    "\n",
    "df['Work'] = df['startTime'].apply(lambda x: 1 if int(x.split(' ')[3].split(':')[0])>=9 and int(x.split(' ')[3].split(':')[0])<=17 and datetime.datetime(2000+int(x.split(' ')[2]),int(x.split(' ')[1]),int(x.split(' ')[2])).weekday()<=4 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Total number of products viewed and products viewed per time spent as features - For test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_list = df['ProductList']\n",
    "\n",
    "df['No_of_Views'] = pd.Series(np.zeros(len(prod_list)))\n",
    "\n",
    "for i in range(len(prod_list)):\n",
    "    string = prod_list[i]\n",
    "    no_prods = int(string.count('/')/4)\n",
    "    prod = string.split(';')\n",
    "    df.loc[i,'No_of_Views']=len(prod)\n",
    "\n",
    "df['Speed'] = (df['No_of_Views'])/(df['Interval']+0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creating Sparse features for categories and subcategories A1,...,A11, B01,...B91, C001,...,C436 - For test data</h3>\n",
    "Each of these columns indicate the number of products viewed in the respective category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1,437):\n",
    "    if(m):\n",
    "        if(m<10):\n",
    "            df['C00'+str(m)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(m>=10 and m<100):\n",
    "            df['C0'+str(m)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(m>=100):\n",
    "            df['C'+str(m)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(m)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[2][-3:] == '0'+str(m) or prod[j].split('/')[2][-3:] == str(m) or prod[j].split('/')[2][-3:]=='00'+str(m)):\n",
    "                if(m<10):\n",
    "                    df.loc[i,'C00'+str(m)] += 1\n",
    "                if(m>=10 and m<100):\n",
    "                    df.loc[i,'C0'+str(m)] += 1\n",
    "                if(m>=100):\n",
    "                    df.loc[i,'C'+str(m)] += 1\n",
    "\n",
    "for l in range(1,92):\n",
    "    if(l):\n",
    "        if(l>=10):\n",
    "            df['B'+str(l)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(l<10):\n",
    "            df['B0'+str(l)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(l)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[1][-2:] == '0'+str(l) or prod[j].split('/')[1][-2:] == str(l)):\n",
    "                if(l<10):\n",
    "                    df.loc[i,'B0'+str(l)] += 1\n",
    "                if(l>=10):\n",
    "                    df.loc[i,'B'+str(l)] += 1\n",
    "            \n",
    "    \n",
    "for k in range(1,12):\n",
    "    if(k>=10):\n",
    "        df['A'+str(k)] = pd.Series(np.zeros(len(prod_list)))\n",
    "    else:\n",
    "        df['A0'+str(k)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(k)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[0][-2:] == '0'+str(k) or prod[j].split('/')[0][-2:] == str(k)):\n",
    "                if(k<10):\n",
    "                    df.loc[i,'A0'+str(k)] += 1\n",
    "                else:\n",
    "                    df.loc[i,'A'+str(k)] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>More Sparse Features using the Product Code - For test data</h3>\n",
    " Third digit after 'D',4th and 5th digits after 'D', 1st and 2nd digits after 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(0,10):\n",
    "    df['E'+str(p)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(p)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[3][3] == str(p)):\n",
    "                df.loc[i,'E'+str(p)] += 1\n",
    "                \n",
    "for o in range(0,100):\n",
    "    if(o>-1):\n",
    "        if(o<10):\n",
    "            df['F0'+str(o)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(o>=10):\n",
    "            df['F'+str(o)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(o)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[3][4:6] == '0' +str(o) or prod[j].split('/')[3][4:6] == str(o)):\n",
    "                if(o<10):\n",
    "                    df.loc[i,'F0'+str(o)] += 1\n",
    "                if(o>=10):\n",
    "                    df.loc[i,'F'+str(o)] += 1    \n",
    "    \n",
    "for n in range(0,100):\n",
    "    if(n>-1):\n",
    "        if(n<10):\n",
    "            df['D0'+str(n)] = pd.Series(np.zeros(len(prod_list)))\n",
    "        if(n>=10):\n",
    "            df['D'+str(n)] = pd.Series(np.zeros(len(prod_list)))\n",
    "#     print(n)\n",
    "    for i in range(len(prod_list)):\n",
    "        string = prod_list[i]\n",
    "        no_prods = int(string.count('/')/4)\n",
    "        prod = string.split(';', no_prods)\n",
    "        for j in range(no_prods):\n",
    "            if(prod[j].split('/')[3][1:3] == '0'+str(n) or prod[j].split('/')[3][1:3] == str(n)):\n",
    "                if(n<10):\n",
    "                    df.loc[i,'D0'+str(n)] += 1\n",
    "                if(n>=10):\n",
    "                    df.loc[i,'D'+str(n)] += 1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Features indicating number of categories and subcategories viewed, per total product views and per time spent - for test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['N_CategoriesA'] = pd.Series(np.zeros(len(prod_list)))\n",
    "for i in range(1,12):\n",
    "    if(i<10):\n",
    "        df['N_CategoriesA'] += df['A0'+str(i)]>0\n",
    "    else:\n",
    "        df['N_CategoriesA'] += df['A'+str(i)]>0\n",
    "df['Cat_PropA'] = df['N_CategoriesA']/df['No_of_Views']\n",
    "df['Cat_SpeedA'] = df['N_CategoriesA']/(df['Interval']+0.01)\n",
    "\n",
    "df['N_CategoriesB'] = pd.Series(np.zeros(len(prod_list)))\n",
    "for i in range(1,92):\n",
    "    if(i<10):\n",
    "        df['N_CategoriesB'] += df['B0'+str(i)]>0\n",
    "    else:\n",
    "        df['N_CategoriesB'] += df['B'+str(i)]>0       \n",
    "df['Cat_PropB'] = df['N_CategoriesB']/df['No_of_Views']\n",
    "df['Cat_SpeedB'] = df['N_CategoriesB']/(df['Interval']+0.01)\n",
    "\n",
    "df['N_CategoriesC'] = pd.Series(np.zeros(len(prod_list)))\n",
    "for i in range(1,437):\n",
    "    if(i>=100):\n",
    "        df['N_CategoriesC'] += df['C'+str(i)]>0\n",
    "    elif(i>=10):\n",
    "        df['N_CategoriesC'] += df['C0'+str(i)]>0\n",
    "    else:\n",
    "        df['N_CategoriesC'] +=df['C00'+str(i)]>0     \n",
    "df['Cat_PropC'] = df['N_CategoriesC']/df['No_of_Views']\n",
    "df['Cat_SpeedC'] = df['N_CategoriesC']/(df['Interval']+0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Saving the dataframe with new features - for Test Data</h3>\n",
    "Note: I used two python files initially (combined them now), one for feature engineering and other to test the model. So this step was only to facilitate that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['ProductList'],axis=1)\n",
    "df.to_csv('/home/hithesh/Desktop/ML Competitions/ECommerce_Analytics_Vidhya/mod_df_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading the dataframe with new features and Dropping Useless or Redundant Features</h3>\n",
    "Note: I used two python files initially (combined them now), one for feature engineering and other to test the model. So this step was only to facilitate that. Redundant features were identified using cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 session_id       startTime         endTime  gender        Date  \\\n",
      "0           0     u16159  15 12 14 18:11  15 12 14 18:12       0  2014-12-15   \n",
      "1           1     u10253  16 12 14 14:35  16 12 14 14:41       1  2014-12-16   \n",
      "2           2     u19037  01 12 14 15:58  01 12 14 15:58       0  2014-12-01   \n",
      "3           3     u14556   23 11 14 2:57   23 11 14 3:00       0  2014-11-23   \n",
      "4           4     u24295  17 12 14 16:44  17 12 14 16:46       1  2014-12-17   \n",
      "\n",
      "   STime  ETime  SHour  EHour  ...  D99  N_CategoriesA  Cat_PropA  Cat_SpeedA  \\\n",
      "0   1091   1092     18     18  ...  0.0            1.0   0.250000    0.990099   \n",
      "1    875    881     14     14  ...  0.0            1.0   0.142857    0.166389   \n",
      "2    958    958     15     15  ...  0.0            1.0   1.000000  100.000000   \n",
      "3    177    180      2      3  ...  0.0            1.0   0.333333    0.332226   \n",
      "4   1004   1006     16     16  ...  0.0            1.0   0.500000    0.497512   \n",
      "\n",
      "   N_CategoriesB  Cat_PropB  Cat_SpeedB  N_CategoriesC  Cat_PropC  Cat_SpeedC  \n",
      "0            1.0   0.250000    0.990099            1.0   0.250000    0.990099  \n",
      "1            1.0   0.142857    0.166389            1.0   0.142857    0.166389  \n",
      "2            1.0   1.000000  100.000000            1.0   1.000000  100.000000  \n",
      "3            1.0   0.333333    0.332226            1.0   0.333333    0.332226  \n",
      "4            1.0   0.500000    0.497512            1.0   0.500000    0.497512  \n",
      "\n",
      "[5 rows x 782 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/hithesh/Desktop/ML Competitions/ECommerce_Analytics_Vidhya/mod_df.csv')\n",
    "print(df.head())\n",
    "features = df.columns\n",
    "features = features.drop(['session_id','startTime','endTime','gender','Unnamed: 0','Date','STime','ETime','NewYear','SMinute','EMinute','Cat_SpeedA','Cat_SpeedB','Cat_SpeedC'])\n",
    "X = df[features]\n",
    "y = df['gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cross Validation by Splitting Training Data</h3>\n",
    "Models like SVM, GradientBoost, Random Forests, XGBoost were tried with adjusting various parameters (max_depth,min_samples_split,learning_rate etc) and evaluated. XGBoost Classifier with n_estimators 10000 gave the best Cross Validation score. Could have done better with the overfitting, but n_estimators 10000 took a lot of time to execute and it was nearing competition closing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Error: 100.0\n",
      "CV_Error: 91.71428571428571 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# model = SVC()\n",
    "# model = GradientBoostingClassifier()\n",
    "# model = RandomForestClassifier()\n",
    "model = XGBClassifier(n_estimators = 10000)\n",
    "model.fit(X_train, y_train)\n",
    "print('Train_Error:',((model.predict(X_train) - y_train) == 0).sum()*100/len(y_train))\n",
    "print('CV_Error:',((model.predict(X_test) - y_test) == 0).sum()*100/len(y_test),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Fitting the model to Full Training Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "       importance_type='gain', interaction_constraints=None,\n",
       "       learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "       n_estimators=10000, n_jobs=0, num_parallel_tree=1,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "       validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Predicting on the Test Set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/home/hithesh/Desktop/ML Competitions/ECommerce_Analytics_Vidhya/mod_df_test.csv')\n",
    "features = df_test.columns\n",
    "sess_id = df_test['session_id']\n",
    "features = features.drop(['session_id','startTime','endTime','Unnamed: 0','Date','STime','ETime','NewYear','SMinute','EMinute','Cat_SpeedA','Cat_SpeedB','Cat_SpeedC'])\n",
    "X_test = df_test[features]\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Converting encoded predicted genders back to male,female and saving the final submission file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['gender'] = pd.Series(pred).apply(lambda x:'male' if x==1 else 'female')\n",
    "final = pd.concat([sess_id,df_test['gender']],axis=1)\n",
    "\n",
    "final.to_csv('/home/hithesh/Desktop/ML Competitions/ECommerce_Analytics_Vidhya/ecomm_sub.csv',header=True , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
